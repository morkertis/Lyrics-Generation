{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing - Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are handling the test file.\n",
    "<br>This is an example run. (Requires pretrained model to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\TomerMeirman\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import Model2Base as mb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First** - Handling vocabulary from the first data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/lyrics_train_set.csv\",header=None)\n",
    "df = df.fillna('')\n",
    "df[2] = df[2] + df[3] + df[4] + df[5] + df[6] \n",
    "df=df.drop([3,4,5,6],axis=1)\n",
    "df.columns=['singer','song','lyrics']\n",
    "\n",
    "df['song_num']=df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_lyrics'] = df.apply(lambda row: mb.clean_text(row.lyrics),axis=1)\n",
    "df['singer_song']= df.apply(lambda row: mb.clean_singer_song(row['singer'],row['song']),axis=1)\n",
    "tokenizer = RegexpTokenizer(r'\\w+|&+')\n",
    "df[\"tokens\"] = df[\"clean_lyrics\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Midis data for information from the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "midis_vec = mb.create_midis_vector(df)\n",
    "number_of_sequences = mb.get_median_length(midis_vec)\n",
    "songs_dict = {}\n",
    "for midi in midis_vec:\n",
    "    midi_file = midi[1]\n",
    "    mat = mb.create_midi_matrix(midi_file, number_of_sequences)\n",
    "    songs_dict[midi[0]] = mat\n",
    "    \n",
    "df=df[df.song_num.isin(songs_dict.keys())]\n",
    "df['clean_lyrics'] = df.apply(lambda row: mb.clean_text(row.lyrics),axis=1)\n",
    "df['singer_song']=df.apply(lambda row: mb.clean_singer_song(row['singer'],row['song']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the different words in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df[\"tokens\"] = df[\"clean_lyrics\"].apply(tokenizer.tokenize)\n",
    "df['ln']= df[\"tokens\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180248 words total, with a vocabulary size of 7525\n",
      "Max sentence length is 1481\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for tokens in df[\"tokens\"] for word in tokens]\n",
    "sentence_lengths = [len(tokens) for tokens in df[\"tokens\"]]\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))\n",
    "print(\"Max sentence length is %s\" % max(sentence_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating tokenizer from the train data so we can reverse the sequences to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(VOCAB)\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(df[\"clean_lyrics\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aranging test set for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/lyrics_test_set.csv\",header=None)\n",
    "test_df = test_df.fillna('')\n",
    "test_df.columns=['singer','song','lyrics']\n",
    "test_df['clean_lyrics'] = test_df.apply(lambda row: mb.clean_text(row.lyrics),axis=1)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df[\"clean_lyrics\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create midis matrices for all test songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "midis_vec = mb.test_create_midis_vector(test_df)\n",
    "number_of_sequences = 221\n",
    "songs_dict = {}\n",
    "for midi in midis_vec:\n",
    "    midi_file = midi[1]\n",
    "    mat = mb.create_midi_matrix(midi_file, number_of_sequences)\n",
    "    songs_dict[midi[0]] = mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0727 19:16:20.399608 13552 deprecation_wrapper.py:119] From C:\\Users\\TomerMeirman\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0727 19:16:20.416469 13552 deprecation_wrapper.py:119] From C:\\Users\\TomerMeirman\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0727 19:16:20.417469 13552 deprecation_wrapper.py:119] From C:\\Users\\TomerMeirman\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0727 19:16:20.747279 13552 deprecation_wrapper.py:119] From C:\\Users\\TomerMeirman\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0727 19:16:20.753261 13552 deprecation.py:506] From C:\\Users\\TomerMeirman\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0727 19:16:20.806120 13552 deprecation_wrapper.py:119] From C:\\Users\\TomerMeirman\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model2_2019_07_26__1512'\n",
    "model = mb.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = [test_sequences[x][0] for x in range(0,len(test_sequences))]\n",
    "melodies = [np.expand_dims(songs_dict[i], 0) for i in range(len(songs_dict))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating songs using our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(123)\n",
    "num_of_songs = 2\n",
    "\n",
    "songs = []\n",
    "for ii in range(len(input_words)):\n",
    "    song = mb.create_song(model, input_words[ii],melodies[ii],lyrics_length=50,num_of_songs=num_of_songs, random_state=5)\n",
    "    songs.append(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse the sequences to text - to view our newly created songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['close to you ',\n",
       "   ' you know you want to know ',\n",
       "   ' its not to me you ',\n",
       "   ' you know the things that you want ',\n",
       "   ' ',\n",
       "   ' ooh ooh ooh oh i know ',\n",
       "   ' baby you still im in my life ',\n",
       "   ' youre so many i say ',\n",
       "   ' you still im'],\n",
       "  ['close to me ',\n",
       "   ' to walk away ',\n",
       "   ' when youre gone at me ',\n",
       "   ' its been to me so ',\n",
       "   ' and it if you feel like so ',\n",
       "   ' its been so you wont you just to me to you ',\n",
       "   ' im in my arms ',\n",
       "   ' and you want me to']],\n",
       " [['if it doesnt really matter ',\n",
       "   ' im not more ',\n",
       "   ' i cant give you ',\n",
       "   ' now i want to be weird ',\n",
       "   ' and so many i have to go ',\n",
       "   ' im not more more ',\n",
       "   ' do it right ',\n",
       "   ' i cant believe the things that i want you ',\n",
       "   ' oh'],\n",
       "  ['if you were my name ',\n",
       "   ' my loneliness is moving back ',\n",
       "   ' oh you got to be ',\n",
       "   ' cant you ',\n",
       "   ' im a man who have before ',\n",
       "   ' i didnt know why it was me ',\n",
       "   ' when you see the same ',\n",
       "   ' you got to be weird ',\n",
       "   ' im in']],\n",
       " [['dear ',\n",
       "   ' i am i cant remember for ',\n",
       "   ' and how you are from ',\n",
       "   ' and if it comes on your feet ',\n",
       "   ' the one of your eyes ',\n",
       "   ' it knows you like to get your head ',\n",
       "   ' i get to get this ',\n",
       "   ' but this is has gone ',\n",
       "   ''],\n",
       "  ['dear ',\n",
       "   ' im not the kind of day ',\n",
       "   ' you can tell you how ',\n",
       "   ' you cant take this ',\n",
       "   ' you cant see you know ',\n",
       "   ' and if it comes away ',\n",
       "   ' i am i dont know it ',\n",
       "   ' im comin to say ',\n",
       "   ' but i cant go ',\n",
       "   ' im']],\n",
       " [['hi and the air ',\n",
       "   ' i see the world ',\n",
       "   ' move on my life in my life ',\n",
       "   ' i just want to get some your love from me ',\n",
       "   ' and then my girlfriend are gonna find my girl ',\n",
       "   ' come on and im like my head on my mind ',\n",
       "   ''],\n",
       "  ['hi my love ',\n",
       "   ' is my life my life has got a lot ',\n",
       "   ' every night ',\n",
       "   ' i know my love is lonely ',\n",
       "   ' im losing of my heart ',\n",
       "   ' and when i got out ',\n",
       "   ' my little girl is a uptown world ',\n",
       "   ' are the things that i can']],\n",
       " [['all the way i got it is you got a little long long ',\n",
       "   ' you aint around you but aint got a lot but but they aint got enough ',\n",
       "   ' but you aint got a lot but just for a man i just been a friend but long one can'],\n",
       "  ['all you aint gonna but you aint around it ',\n",
       "   ' but you got a big day ',\n",
       "   ' you got a big but they aint got a lot ',\n",
       "   ' but i just got to hear you got a little more but they aint it around youre a friend ',\n",
       "   ' when you']]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_map = [tokenizer.sequences_to_texts(song) for song in songs]\n",
    "reversed_sentences = []\n",
    "for i in range(len(input_words)):\n",
    "    reversed_sentences.append([x.split('eos') for x in reverse_word_map[i]])\n",
    "reversed_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
